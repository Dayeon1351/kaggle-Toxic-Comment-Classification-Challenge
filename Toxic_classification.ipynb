{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dislab/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys, os, re, csv, math, codecs, numpy as np, pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D, MaxPool1D, Flatten, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE='./data/glove.6B.50d.txt'\n",
    "TRAIN_DATA_FILE='./data/train.csv'\n",
    "TEST_DATA_FILE='./data/test.csv'\n",
    "MODEL_WEIGHTS_FILE = './toxic_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50 # 단어를 몇 차원으로 임베딩할 것인가(how many dimensions use to embed word?) \n",
    "max_features = 20000 # 몇개의 단어를 주요한 특징으로 볼 것인가(How many words will be the main feature?) \n",
    "maxlen = 100 # 한 comment에서 가져올 수 있는 단어의 최대 갯수(The maximum number of words a comment can get?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Toxic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test = pd.read_csv(TEST_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values # comment_text만 가져와서 fillna를 통해 nan를 거른다.\n",
    "                                                                   # Just import comment_text and filter nan through fillna.\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"] # 사용할 컬럼들(to use columns)\n",
    "y = train[list_classes].values # labels of comment_text\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values # Do the same things for test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features) # max_features 만큼의 단어를 Tokenize하기 위한 틀 생성.\n",
    "                                              # Create a frame to Tokenize words as many as max_features.\n",
    "tokenizer.fit_on_texts(list(list_sentences_train)) # just fit\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train) # Tokenize(Transform word into number)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test) # Tokenize(Transform word into number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  688    75     1   126   130   177    29   672  4511 12052  1116    86\n",
      "    331    51  2278 11448    50  6864    15    60  2756   148     7  2937\n",
      "     34   117  1221 15188  2825     4    45    59   244     1   365    31\n",
      "      1    38    27   143    73  3462    89  3085  4583  2273   985]]\n"
     ]
    }
   ],
   "source": [
    "print(np.reshape(list_tokenized_train[0], (1,-1))) # 각 문장(comment)의 단어들을 1(가장 많이 사용된 단어) ~ 20000(2만번째로 많이 사용된 단어) 으로 정수화함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen) # 모든 단어는 각자 다른 길이를 갖고 있으므로 작은 길이의 문장에 \n",
    "                                                         # padding을 해줌으로서 모든 문장의 길이를 maxlen로 맞춰줌\n",
    "                                                         # All comment_texts are different in length, \n",
    "                                                         # so 0 is filled as much as maxlen in small sentences\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen) # do the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  4583,  2273,   985],\n",
       "       [    0,     0,     0, ...,   589,  8377,   182],\n",
       "       [    0,     0,     0, ...,     1,   737,   468],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  3509, 13674,  4528],\n",
       "       [    0,     0,     0, ...,   151,    34,    11],\n",
       "       [    0,     0,     0, ...,  1627,  2056,    88]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t # 모든 문장의 길이를 maxlen으로 통일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52042 , -0.8314  ,  0.49961 ,  1.2893  ,  0.1151  ,  0.057521,\n",
       "       -1.3753  , -0.97313 ,  0.18346 ,  0.47672 , -0.15112 ,  0.35532 ,\n",
       "        0.25912 , -0.77857 ,  0.52181 ,  0.47695 , -1.4251  ,  0.858   ,\n",
       "        0.59821 , -1.0903  ,  0.33574 , -0.60891 ,  0.41742 ,  0.21569 ,\n",
       "       -0.07417 , -0.5822  , -0.4502  ,  0.17253 ,  0.16448 , -0.38413 ,\n",
       "        2.3283  , -0.66682 , -0.58181 ,  0.74389 ,  0.095015, -0.47865 ,\n",
       "       -0.84591 ,  0.38704 ,  0.23693 , -1.5523  ,  0.64802 , -0.16521 ,\n",
       "       -1.4719  , -0.16224 ,  0.79857 ,  0.97391 ,  0.40027 , -0.21912 ,\n",
       "       -0.30938 ,  0.26581 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE)) # glove의 (단어, 벡터)를 가져옴\n",
    "                                                                                     # Get (word, vector) of glove\n",
    "embeddings_index.get(\"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.020940464, 0.6441042)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values()) # glove의 dict(embeddings_index)에서 벡터만 list 로 변환\n",
    "                                               # Convert vectors of glove's dict(embeddings_index) into list\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std() # glove 벡터들의 평균과 표준편차를 구함\n",
    "                                                   # Obtain the mean and standard deviation of glove vectors\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make embedding maxtirx based GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index # tokenizer에 의해 얻어진 모든 단어들의 배열\n",
    "                                  # an array of all the words obtained by the tokenizer\n",
    "nb_words = min(max_features, len(word_index)) # glove의 영어단어는 너무 많으므로 max_features에 맞출지 word_index에 맞출지 정함\n",
    "                                              # Because glove has too many English words, \n",
    "                                              # it determines whether the number of words matches max_features or word_index\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size)) # (nb_words X embed_size) 크기의 벡터 필드를 설정\n",
    "                                                                               # Set a vector field of size (nb_words X embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if i >= max_features: \n",
    "        continue # 2만개 이상은 무시(Ignore more than max_feature.)\n",
    "    embedding_vector = embeddings_index.get(word) # comment에서 사용된 단어의 벡터값을 glove에서 가져옴\n",
    "                                                  # The vector value of the word used in comment is taken from glove\n",
    "    \n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector # embedding_matrix에 사용된 단어의 벡터값을 덮어 씌움\n",
    "                                               # Override embedding_matrix with the vector value defined in glove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dislab/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,)) # X_t가 (maxlen, -1)인지 재확인 및 reshape\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp) # inp를 (max_features X embed_size)의 행렬에 weights의 가중치로 embedding\n",
    "\n",
    "x = Conv1D(64, kernel_size=3, padding='same', name='conv1')(x) # CNN\n",
    "x = BatchNormalization()(x) # batch normalization\n",
    "x = ELU()(x) # ELU\n",
    "x = MaxPool1D()(x) # maxpooling\n",
    "\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x) # RNN중 하나인 LSTM사용 and maxpool\n",
    "x = GlobalMaxPool1D()(x) # maxpolling\n",
    "\n",
    "x = Dense(50, activation=\"relu\")(x) # Fully connection layer\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x) # 결론\n",
    "\n",
    "\n",
    "model = Model(inputs=inp, outputs=x) # 모델의 input, output설정\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # optimizer는 adam loss는 binary_crossentropy로 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/10\n",
      "143613/143613 [==============================] - 298s 2ms/step - loss: 0.0607 - acc: 0.9788 - val_loss: 0.0504 - val_acc: 0.9819\n",
      "Epoch 2/10\n",
      "143613/143613 [==============================] - 296s 2ms/step - loss: 0.0462 - acc: 0.9827 - val_loss: 0.0479 - val_acc: 0.9824\n",
      "Epoch 3/10\n",
      "143613/143613 [==============================] - 298s 2ms/step - loss: 0.0415 - acc: 0.9841 - val_loss: 0.0478 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "143613/143613 [==============================] - 301s 2ms/step - loss: 0.0380 - acc: 0.9851 - val_loss: 0.0468 - val_acc: 0.9831\n",
      "Epoch 5/10\n",
      "143613/143613 [==============================] - 301s 2ms/step - loss: 0.0350 - acc: 0.9859 - val_loss: 0.0496 - val_acc: 0.9821\n",
      "Epoch 6/10\n",
      "143613/143613 [==============================] - 300s 2ms/step - loss: 0.0324 - acc: 0.9870 - val_loss: 0.0508 - val_acc: 0.9826\n",
      "Epoch 7/10\n",
      "143613/143613 [==============================] - 300s 2ms/step - loss: 0.0296 - acc: 0.9880 - val_loss: 0.0546 - val_acc: 0.9817\n",
      "Epoch 8/10\n",
      "143613/143613 [==============================] - 306s 2ms/step - loss: 0.0274 - acc: 0.9888 - val_loss: 0.0565 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.000500000023749.\n",
      "Epoch 9/10\n",
      "143613/143613 [==============================] - 302s 2ms/step - loss: 0.0235 - acc: 0.9905 - val_loss: 0.0636 - val_acc: 0.9813\n",
      "Epoch 10/10\n",
      "143613/143613 [==============================] - 300s 2ms/step - loss: 0.0214 - acc: 0.9914 - val_loss: 0.0738 - val_acc: 0.9818\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0000001)\n",
    "\n",
    "callbacks = [learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                                       # approach to get optimal value by gradually decreasing learning_rate\n",
    "             #EarlyStopping('val_loss', patience=2), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                                       # If val_loss deviates from the optimal value, \n",
    "                                                                       # learning stops even if epoch remains.\n",
    "             ModelCheckpoint(MODEL_WEIGHTS_FILE, save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "                                                                                                            # Always store the optimal weights that have been shown so far \n",
    "                                                                                                            # while learning the model\n",
    "\n",
    "history = model.fit(X_t, y, batch_size=32, epochs=10, validation_split=0.1, callbacks=callbacks); # 학습 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 33s 216us/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([X_te], batch_size=1024, verbose=1) # model에 test data를 넣고 예측\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv') # 예측값을 저장할 csv파일\n",
    "sample_submission[list_classes] = y_test # csv에 저장할 값을 설정\n",
    "sample_submission.to_csv('./data/submission.csv', index=False) # csv파일에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make graph that compare loss and val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dislab/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f7f8eb590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                     'training': [ math.sqrt(loss) for loss in history.history['loss'] ],\n",
    "                     'validation': [ math.sqrt(loss) for loss in history.history['val_loss'] ]})\n",
    "#ax = loss.ix[:,:].plot(x='epoch', figsize={1,30}, grid=True)\n",
    "ax = loss.ix[:,:].plot(x='epoch', grid=True)\n",
    "ax.set_ylabel(\"root mean squared error\")\n",
    "ax.set_ylim([0.0,0.3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
